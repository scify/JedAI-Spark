package Experiments

import java.util.Calendar

import SparkER.DataStructures.WeightedEdge
import SparkER.EntityClustering.{ConnectedComponentsClustering, EntityClusterUtils}
import SparkER.SimJoins.Commons.CommonFunctions
import SparkER.SimJoins.SimJoins.{EDJoin, FastSS}
import SparkER.Wrappers.{CSVWrapper, JSONWrapper}
import org.apache.log4j.{FileAppender, Level, LogManager, SimpleLayout}
import org.apache.spark.storage.StorageLevel
import org.apache.spark.{SparkConf, SparkContext}

/**
  * Tests the FastSSJoin implementation
  **/
object FastSSExp {
  def main(args: Array[String]): Unit = {
    /* Dataset to test */
    val dataset = "restaurant"

    /* Base path where the dataset is located */
    val basePath = "datasets/dirty/" + dataset + "/"

    /* Profiles to join */
    val filePath = basePath + dataset + ".csv"

    /* Groundtruth */
    val gtPath = basePath + dataset + "_groundtruth.csv"

    /** Log file */
    val logPath = "log.txt"

    /** Spark configuration */
    val conf = new SparkConf()
      .setAppName("Main")
      .setMaster("local[*]")
      .set("spark.default.parallelism", "4")
      .set("spark.executor.memory", "10g")

    val sc = new SparkContext(conf)

    val log = LogManager.getRootLogger
    log.setLevel(Level.INFO)
    val layout = new SimpleLayout()
    val appender = new FileAppender(layout, logPath, false)
    log.addAppender(appender)

    /* Loads the profiles */
    val profiles = CSVWrapper.loadProfiles2(filePath, realIDField = "id", header = true)

    val t1 = Calendar.getInstance().getTimeInMillis
    log.info("[FastSS] Join: matches_name")
    val name = CommonFunctions.extractField(profiles, "name")
    name.persist(StorageLevel.MEMORY_AND_DISK)
    name.count()

    val matches_name = FastSS.getMatches(name, threshold = 2)
    name.unpersist()
    val t2 = Calendar.getInstance().getTimeInMillis

    log.info("[FastSS] Join: addr")
    val addr = CommonFunctions.extractField(profiles, "addr")
    addr.persist(StorageLevel.MEMORY_AND_DISK)
    addr.count()

    val matches_addr = FastSS.getMatches(addr, threshold = 2)
    addr.unpersist()
    val t3 = Calendar.getInstance().getTimeInMillis


    log.info("[FastSS] Compute common matches")
    val matches = matches_name.intersection(matches_addr)
    matches.persist(StorageLevel.MEMORY_AND_DISK)
    val common = matches.count()
    matches_name.unpersist()
    matches_addr.unpersist()
    log.info("[FastSS] Common matches name - addr: " + common)

    val t4 = Calendar.getInstance().getTimeInMillis

    val joinTime = (t2 - t1) + (t3 - t2)
    val intTime = t3 - t4

    log.info("[FastSS] Global join+verification time (s) " + joinTime / 1000.0)
    log.info("[FastSS] Intersection time (s) " + intTime / 1000.0)

    /** Performs the transitive closure */
    val t8 = Calendar.getInstance().getTimeInMillis
    val clusters = ConnectedComponentsClustering.getClusters(profiles, matches.map(x => WeightedEdge(x._1, x._2, 0)), 0)
    clusters.persist(StorageLevel.MEMORY_AND_DISK)
    val cn = clusters.count()
    val t9 = Calendar.getInstance().getTimeInMillis
    log.info("[FastSS] Number of clusters " + cn)
    log.info("[FastSS] Clustering time (s) " + (t9 - t8) / 1000.0)

    log.info("[FastSS] Total time (s) " + (t9 - t1) / 1000.0)

    /** Loads the groundtruth */
    val groundtruth = CSVWrapper.loadGroundtruth(gtPath)

    /** Converts the ids in the groundtruth to the autogenerated ones */
    val realIdIds = sc.broadcast(profiles.map { p =>
      (p.originalID, p.id)
    }.collectAsMap())

    var newGT: Set[(Int, Int)] = null
    newGT = groundtruth.map { g =>
      val first = realIdIds.value.get(g.firstEntityID)
      val second = realIdIds.value.get(g.secondEntityID)
      if (first.isDefined && second.isDefined) {
        val f = first.get
        val s = second.get
        if (f < s) (f, s) else (s, f)
      }
      else {
        (-1, -1)
      }
    }.filter(_._1 >= 0).collect().toSet

    log.info("[FastSS] Groundtruth size " + groundtruth.count())
    log.info("[FastSS] New groundtruth size " + newGT.size)

    val gt = sc.broadcast(newGT)

    /** Computes precision and recall */
    val pcpq = EntityClusterUtils.calcPcPqCluster(clusters, gt)
    log.info("[FastSS] PC " + pcpq._1)
    log.info("[FastSS] PQ " + pcpq._2)

    val f1 = 2 * ((pcpq._1 * pcpq._2) / (pcpq._1 + pcpq._2))
    log.info("[FastSS] F1 " + f1)
  }
}
